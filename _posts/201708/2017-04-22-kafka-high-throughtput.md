---
title: Kafka吞吐量高的原因
date: 2017-04-22 17:32:31 Z
categories: [kafka,middleware]
layout: post
---
摘自：[阿里云测试](https://yq.aliyun.com/articles/67003?spm=5176.8269312.601338.12.cLRfQp)

Kafka，这款为大数据而生的消息中间件，以其百万级TPS的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用，被LinkedIn，Uber, Twitter, Netflix等大公司所采纳，而storm，spark，flink等大数据流处理或批处理平台都有Kafka的相关插件支持。
那么，Kafka的百万级TPS是如何做到的呢？有很多相关的分析，比如异步IO，PageCache，异步刷盘，消费过程零拷贝，Batch等，这些都对，但是没有一个直观的说明，这众多因素中，哪一个才是杀手锏呢？

### 测试机器
一台物理机部署Kafka，另一台物理机施加压力，每个producer异步发送，异步统计结果；本文所涉及的机器配置都是24核48G内存SSD盘

当单个消息体为50字节时（with batch），kafka单机的吞吐量确实表现出色，能达到百万级。可是当单个消息体为5k字节时，TPS极速下降，只有大约3万多，少了两个数量级。对此，可能有人会说那是因为网卡打满了，还有就是因为消息体变大，每次能batch的数量变少了，导致整体TPS下降。都有可能，笔者测试时网卡虽然没有打满，却确实是负载比较高了。

50字节时，Kafka no batch（batch size设为1）时的吞吐量只有15万多，只有启用batch时的十分之一。

### 结论

Kafka达到百万级TPS的杀手锏就是**batch**！
batch, 简单说就是把多个消息打包一次性发过去，对于在线交易系统来说，这通常不是一个好的选择，会导致消息大量丢失或者大量重复，延迟也会加大。但对于大数据领域来说，由于大部分都是离线半离线的计算，对数据可靠性要求没有那么高，但追求高吞吐量。Kafka为适应大数据，选择了batch，因此，赢得了大数据的欢迎。